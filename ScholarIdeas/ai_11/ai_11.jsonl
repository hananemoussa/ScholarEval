{"statement": "The experimental results are limited to 21 competitive programming problems, raising concerns about generalizability.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "The comparison between CodeLLama (based on LLama2) and LLama3(.1) for SFT vs. PT may be problematic, as the use of distinct model versions could affect the observed diversity differences.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "CodeBERTScore is outdated for neural diversity evaluation, and more current options include UniXCoder or CodeExecutor should be considered.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The major concerns are the meaningfulness of studying diversity in code generation where usually only one correct output exists, and the generalizability of conclusions to general-domain open-ended generations.", "type": "weakness", "axis": "contribution", "severity": "major"}
{"statement": "There is no evaluation of correctness metrics, and representative benchmarks like HumanEval and BigCodeBench should be included.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "The open models included in the evaluation are not diverse enough, and other Code LLMs such as StarCoder2 and CodeQwen should be used.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The experiments are Python-only and evaluations should be conducted on more programming languages.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "There is a lack of motivation to conduct investigations on code generation over text generation, and sufficient explanations should be provided for this choice.", "type": "weakness", "axis": "contribution", "severity": "minor"}
