{"statement": "The experimental protocol focuses on three specific tasks, while GenomeOcean is intended to be generic. The authors should either (1) design a more comprehensive set of tasks across various domains to evaluate the model's generalizability or (2) focus on fewer tasks with more in-depth analysis to understand the specific genomic knowledge captured by the network.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "Interpreting the performance differences between Evo, GenSLM, and GenomeOcean is challenging since the authors do not discuss the pre-training data or the extent of overlap between the downstream datasets and the pre-training datasets for each model, making it difficult to gain insights from the comparison.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "Using GUE to determine which tokenization, model architecture, and training objective to be used for GenomeOcean seems arbitrary and potentially incongruous. The representations learned using these modeling decisions will be optimized for the relatively narrow set of tasks presented in GUE, and may have very little generalizability.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "Given the prevalence of CNN-based models in genome sequence modeling, the authors should also consider CNN-based architectures such as GPN or LOGO in their preliminary architecture experiments.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The plan is weakly motivated - why are generated genome sequences from GenomeOcean useful? The other generative models discussed in the paper, such as GenSLM and Evo, are employed in highly specific and impactful contexts. Without demonstrating a similarly practical and realistic use case, the contributions of GenomeOcean remain quite limited.", "type": "weakness", "axis": "contribution", "severity": "major"}
{"statement": "The choice to evaluate performance on the Genome Understanding Evaluation benchmark may dilute the insights gained. Based on my understanding of the benchmark, the train/val/test splits in the datasets are not made while accounting for homology or sequence similarity, which may lead to data leakage and make it unclear whether the models are truly capturing biological function/structure.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "Using other genomic foundation models as a method to discriminate generated sequences in the proposed evaluation metric may be a limitation, as the metric would suffer from inherent biases in the existing FMs. A simple baseline agnostic of existing FMs such as phylogenetic distance between sequences would be interesting to see.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "While the proposed evaluation metrics have a reasonable setup, the tasks evaluated (e.g. species classification) lack strong correlation with the functional validity of the generated sequences, which is highly relevant for real world utility of GenomeOcean.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "The evaluation of common genomic FM modelling decisions is a valuable contribution to the community.", "type": "strength", "axis": "contribution", "severity": "minor"}
