{"statement": "The plan presents a novel framework for predicting LLM performance using a generic assessor, addressing a critical challenge in the fast-evolving landscape of large language models.", "type": "strength", "axis": "contribution", "severity": "major"}
{"statement": "The plan would contribute to the understanding of generalizability by highlighting the limitations of predictive power in out-of-distribution scenarios, prompting further investigation into LLM behavior across diverse tasks.", "type": "strength", "axis": "contribution", "severity": "minor"}
{"statement": "The plan addresses a practical and pressing issue in NLP\u2014efficiently predicting LLM performance without extensive evaluation on large datasets.", "type": "strength", "axis": "contribution", "severity": "major"}
{"statement": "The framework introduces a novel approach that combines a small set of reference evaluations with instance-specific features to build a generic assessor capable of predicting LLM performance on new instances.", "type": "strength", "axis": "contribution", "severity": "major"}
{"statement": "The approach of averaging word vectors from OpenAI embeddings and Word2Vec to form a vector representing the entire prompt seems like it removes a lot of information, and alternative methods for instance feature representation are not sufficiently explored or justified.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The model selection approach of picking the LLM with the highest predicted performance value rather than reporting each individual model performance is non-standard and lacks sufficient justification.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The proposed method shares similarities with existing approaches, such as benchmark subsampling strategies and TinyBenchmarks, and the plan does not sufficiently compare with or differentiate itself from these methods, which limits the perceived originality.", "type": "weakness", "axis": "contribution", "severity": "major"}
{"statement": "While the significant drop in predictive performance in out-of-distribution scenarios is acknowledged, the plan lacks a thorough analysis of the causes and potential solutions to mitigate this issue.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "Some methodological details are not fully elaborated, such as the specific algorithms and parameters used for clustering and factor analysis in reference instance selection, and the criteria for choosing hyperparameters and classifiers are also not described in depth.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The use of OpenAI embeddings as instance-specific features may limit the generalizability and accessibility of the method, particularly for those without access to these embeddings.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The experiments focus on tasks with binary correctness metrics, and the applicability of the method to tasks with more complex or continuous evaluation metrics is not explored, which limits the understanding of its generality.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The plan lacks detailed quantitative comparisons with existing methods, making it difficult to assess the advantages or disadvantages of the proposed approach in terms of predictive accuracy and computational efficiency.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "Despite having perhaps hundreds of potential strong baseline methods to compare against, the authors compare their work only to their own constructed assessor baselines, more akin to ablation studies, and do not compare their method to existing baseline methods for predicting model performance.", "type": "weakness", "axis": "soundness", "severity": "major"}
