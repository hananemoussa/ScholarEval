{"statement": "The ACS selection process operates independently of any machine learning model training, which means it does not necessarily guarantee an 'optimal' subset for the intended learning tasks, raising concerns about its effectiveness in selecting subsets that are truly beneficial for model performance.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "It remains unclear how the ACS method addresses key issues associated with LLM-generated synthetic data, such as deviations in distribution from real-world data and imbalanced class distributions, and how it ensures that the selected subset effectively mitigates these potential issues in synthetic datasets.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "The plan lacks clear guidance on how to determine the value of k (percentage of data) when trying to get a representative subset of the whole dataset using the ACS method.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The plan would benefit from including an ablation study analyzing the impact of the two constraints used in ACS (maximum nearest neighbors constraint and minimum similarity threshold constraint) to clarify the role each constraint plays in the sampling process.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The plan only compares ACS with a few basic sampling approaches (random and k-means clustering) and should include more relevant baselines, such as Alpagasus, core-set selection strategies, active learning strategies, or dataset cartography to provide a more comprehensive view of ACS's advantages and limitations.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "The plan does not address how the proposed ACS method's computational complexity scales with larger datasets.", "type": "weakness", "axis": "soundness", "severity": "minor"}
{"statement": "The evaluation of ACS strategy uses only 2-3 rather simple datasets (sentiment analysis and relation extraction), and would benefit from including more complex datasets such as GLUE or SuperGLUE benchmark datasets.", "type": "weakness", "axis": "soundness", "severity": "major"}
{"statement": "The synthetic samples are generated only from a single closed large language model (GPT-3.5), and the evaluation should include samples generated from open-source models (LLaMA, Mistral, Zephyr) to show better generalizability of the results.", "type": "weakness", "axis": "soundness", "severity": "major"}